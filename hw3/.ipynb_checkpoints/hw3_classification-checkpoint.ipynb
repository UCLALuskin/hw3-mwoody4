{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcce680",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6cb8f042ebb7b7bbab256434910ef60",
     "grade": false,
     "grade_id": "cell-b1217afff8bc58c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 3: Machine learning\n",
    "\n",
    "In this assignment, we'll practice the classification skills from machine learning. We'll use the precinct-level voting data to predict support for Prop 21 (rent control) on the 2020 ballot. For example, we might expect the share of renters to be an important predictor.\n",
    "\n",
    "We'll also review joins as we prepare the data.\n",
    "\n",
    "Start by loading the 2020 elections results from LA County into a `pandas` dataframe, `voteDf`. (This is exactly the same data as we will use next week in the clustering lectures; I put another copy of the data file in the assignment GitHub folder to make things easier.)\n",
    "\n",
    "### Policy on ChatGPT / AI\n",
    "\n",
    "This is the same as in HWs 1 and 2. Please review those guidelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce9f07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43e87542bbd93eba65b63d1df946b8b1",
     "grade": false,
     "grade_id": "cell-c4f721042cd05425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please help me grade by observing the following:\n",
    " \n",
    "* Do not rename this notebook (that messes up the autograder)\n",
    "* Do not include large sections of output (that makes it hard to find your code). For example, use `df.head()` to show the first few rows, rather than printing an entire dataframe. The same goes for printing long strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f4f8fa1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30347d5ed1e8164b2c06eb48609ba2cc",
     "grade": false,
     "grade_id": "cell-2ff091f01ca8b647",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4313\n",
      "   county    srprec  addist  cddist  sddist  bedist  TOTREG  DEMREG  REPREG  \\\n",
      "0      19  0050005A      36      25      21       1    1974       0       0   \n",
      "1      19  0050014A      36      25      21       1     697       0       0   \n",
      "2      19  0050022A      36      27      25       1      61       0       0   \n",
      "3      19  0050024A      41      27      25       1       0       0       0   \n",
      "4      19  0050025A      36      25      25       1       5       0       0   \n",
      "\n",
      "   AIPREG  ...  PR_23_Y  PR_24_N  PR_24_Y  PR_25_N  PR_25_Y  SENAIP01  \\\n",
      "0       0  ...      430      945      771     1304      398         0   \n",
      "1       0  ...      100      314      223      427      116         0   \n",
      "2       0  ...       10       27       22       35       15         0   \n",
      "3       0  ...        0        0        0        0        0         0   \n",
      "4       0  ...        1        2        3        1        3         0   \n",
      "\n",
      "   SENDEM01  SENDEM02  SENLIB01  SENREP01  \n",
      "0       524         0         0      1197  \n",
      "1       163         0         0       373  \n",
      "2        20         0         0        33  \n",
      "3         0         0         0         0  \n",
      "4         2         0         0         3  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load voter data from HW 3 folder\n",
    "voteDf = pd.read_csv('/Users/markwoody/Desktop/UP 213/hw3-mwoody4/hw3/c037_g20_sov_data_by_g20_srprec.csv')\n",
    "\n",
    "print(len(voteDf))\n",
    "print(voteDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55c4df1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cb332b1f272ab5349b67d3bf2b76c41",
     "grade": true,
     "grade_id": "cell-82c4c318b68ac93b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "assert len(voteDf) == 4313\n",
    "assert isinstance(voteDf, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ff214",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f70f7dbb484fc1f79771108c7bc0002",
     "grade": false,
     "grade_id": "cell-8e73935274cd6bac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To do some prediction, we'll want to add variables from (say) the census or other sources.\n",
    "For that, we need the lookup file that matches precincts to census blocks and tracts. [You can find it here](https://statewidedatabase.org/d10/g20_geo_conv.html), or just use the file `c037_g20_sr_blk_map.csv` in your GitHub repository. (Note that there are several types of precincts; the ones that we are using here are called `srprec`.) \n",
    "\n",
    "Each precinct intersects with many census blocks. The `pctsrprec` column tells you how much of the precinct lies within that block. For example, in the first few rows of `c037_g20_sr_blk_map.csv`, you'll see 49 different rows for precinct `0050003A`, each matching to a different census block, with the `pctsrprec` column adding up to 100.\n",
    "\n",
    "Our aim is to create a new dataframe with the vote counts (for all of the propositions and other races) aggregated to census tract. This is a multi-stage process, so let's do this step by step.\n",
    "\n",
    "In this step, you should:\n",
    "- load in the lookup data into a new dataframe, `lookupDf`\n",
    "- join the voting dataframe to the lookup dataframe using `srprec`, to create a new dataframe called `joinDf`. This is a 1:many join, since there are many census blocks per precinct. Do an inner join, as the Null values are not going to be useful to us. (In other words, throw away any lookups that don't match a precinct.)\n",
    "- make sure that `srprec` is the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82282498",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "175587793ace31f97af20b41f50d9ae4",
     "grade": false,
     "grade_id": "cell-c7ed8bd92abd47eh",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tract  block  blkreg  srtotreg  pctsrprec  blktotreg  pctblk  \\\n",
      "srprec                                                                    \n",
      "0050005A  910804   1220       2    1998.0   0.100100          2   100.0   \n",
      "0050005A  910805   1000       8    1998.0   0.400400          8   100.0   \n",
      "0050005A  910805   1001      30    1998.0   1.501502         30   100.0   \n",
      "0050005A  910805   1002      38    1998.0   1.901902         38   100.0   \n",
      "0050005A  910805   1004      15    1998.0   0.750751         15   100.0   \n",
      "\n",
      "          county  addist  cddist  ...  PR_23_Y  PR_24_N  PR_24_Y  PR_25_N  \\\n",
      "srprec                            ...                                       \n",
      "0050005A      19      36      25  ...      430      945      771     1304   \n",
      "0050005A      19      36      25  ...      430      945      771     1304   \n",
      "0050005A      19      36      25  ...      430      945      771     1304   \n",
      "0050005A      19      36      25  ...      430      945      771     1304   \n",
      "0050005A      19      36      25  ...      430      945      771     1304   \n",
      "\n",
      "          PR_25_Y  SENAIP01  SENDEM01  SENDEM02  SENLIB01  SENREP01  \n",
      "srprec                                                               \n",
      "0050005A      398         0       524         0         0      1197  \n",
      "0050005A      398         0       524         0         0      1197  \n",
      "0050005A      398         0       524         0         0      1197  \n",
      "0050005A      398         0       524         0         0      1197  \n",
      "0050005A      398         0       524         0         0      1197  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load census block data from HW 3 folder\n",
    "lookupDf = pd.read_csv('/Users/markwoody/Desktop/UP 213/hw3-mwoody4/hw3/c037_g20_sr_blk_map.csv')\n",
    "\n",
    "# Identify srprec as the index for voteDF and lookupDF (Lect. 3a)\n",
    "lookupDf.set_index('srprec', inplace=True)\n",
    "voteDf.set_index('srprec', inplace=True)\n",
    "\n",
    "# Join voter data with census block data. Perform 1:many (inner) spatial join capturing all census blocks per precinct\n",
    "joinDf = lookupDf.join(voteDf, how='inner')\n",
    "\n",
    "print(joinDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a3f2f2f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "147f4a825287b7695a6d4d319621502d",
     "grade": true,
     "grade_id": "cell-286dda81152bd482",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77704\n",
      "77703\n",
      "77703\n",
      "168427815\n"
     ]
    }
   ],
   "source": [
    "print(len(lookupDf))\n",
    "print(len(joinDf))\n",
    "print(joinDf.county.count())\n",
    "print(joinDf.TOTREG.sum())\n",
    "assert joinDf.index.name=='srprec'\n",
    "assert len(lookupDf)==77704\n",
    "assert len(joinDf)==77703\n",
    "assert joinDf.county.count()==77703\n",
    "assert joinDf.TOTREG.sum()==168427815"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6befe423",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "117929222e3f611a729351cee5825c39",
     "grade": false,
     "grade_id": "cell-7bcea0e4d8ff0da9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's calculate vote shares on Prop 21 and in the presidential race for each census tract. \n",
    "\n",
    "This is slightly tricky, because your data frame `joinDf` will have multiple rows per tract (because the precinct geography does not match the census geography). For example, the following code shows you which precincts intersect with tract 119342. \n",
    "\n",
    "13.65% of the first precinct listed, `9004204A`, is in tract 119342."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15750cae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b06c7452a13ccb2821cff6520a639b38",
     "grade": false,
     "grade_id": "cell-64a15291025f017a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "joinDf[joinDf.tract==119342][['tract','pctsrprec']].sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7067641",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ed88626d5f19d730a72451bb6d4b0fd",
     "grade": false,
     "grade_id": "cell-929fd94be63a3489",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So to aggregate to tracts, you should:\n",
    "- for each relevant column, multiply the number of votes by `pctsrprec`, and divide by 100 (because `pctsrprec` is a percentage, not a fraction)\n",
    "- group by census tract and sum those relevant columns, to create a new dataframe called `tractVotes`. It should have columns `PR_21_N`, `PR_21_Y`, `PRSDEM01`, `PRSREP01`, etc.\n",
    "\n",
    "This will give us our estimate of votes at the tract level.\n",
    "\n",
    "*Hint*: You can pass multiple columns to `groupby`. E.g. `df.groupby('groupcol')[['col1','col2','col3']].sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3d77819",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf5ab9300c3d2259add243d0bbe32ab5",
     "grade": false,
     "grade_id": "cell-863ef266d322296a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Find relevant variables \n",
    "# print(joinDf.columns.tolist())\n",
    "\n",
    "# We are focusing on Prop 21 so we will include the variables for Prop 21 votes and voter parties: 'PRSAIP01', 'PRSDEM01', 'PRSGRN01', 'PRSLIB01', 'PRSPAF01', 'PRSREP01', 'PR_21_N', 'PR_21_Y'\n",
    "prop21 = ['PRSAIP01', 'PRSDEM01', 'PRSGRN01', 'PRSLIB01', 'PRSPAF01', 'PRSREP01', 'PR_21_N', 'PR_21_Y']\n",
    "\n",
    "# Calculate the number of votes in the precinct attributable to each block because precincts exist in many tracts\n",
    "# For all relevant variables, create a new variable that multiplies to precinct % and votes and divide by 100\n",
    "for col in prop21:\n",
    "    joinDf[col] = joinDf[col] * (joinDf['pctsrprec'] / 100)\n",
    "    \n",
    "# Aggregate the precincts to tracts: Summarize the votes in each precinct to each tract \n",
    "tractVotes = joinDf.groupby('tract')[prop21].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a8c0926",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2879397fb6221fd24945a2607e48277",
     "grade": true,
     "grade_id": "cell-d616b48580427e62",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2338\n",
      "2021486.9997128805\n"
     ]
    }
   ],
   "source": [
    "print(len(tractVotes))\n",
    "print(tractVotes.PR_21_Y.sum())\n",
    "\n",
    "# Autograding tests - do not edit\n",
    "assert len(tractVotes)==2338\n",
    "assert tractVotes.PR_21_Y.sum().round() == 2021487"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbec5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bac4104c9191b477355b658354b517b3",
     "grade": false,
     "grade_id": "cell-5d1fa0f9a1e656b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's get a dataframe of some relevant census variables, using the Census Bureau API. Check back to the Week 1 example and the first homework.\n",
    "\n",
    "Create a dataframe, `censusDf`, with ACS 2019 (5 year) tract-level data for LA County, and variables for Tenure (B25003_001E, B25003_002E, B25003_003E) and median household income (B19013_001E). Add a column with the percent of renters, called `pct_renter`.\n",
    "\n",
    "Rename the median HH income column `median_hh_income`, which is more meaningful.\n",
    "\n",
    "Why use ACS 2019 rather than a more recent vintage? Well, the census tract boundaries change after each decennial census (i.e., in 2020), and the precinct-to-tract files we used above map to the pre-2020 census boundaries.\n",
    "\n",
    "As a reminder, here's the Census API [list of tables](https://api.census.gov/data/2019/acs/acs5/variables.html), and [here are examples that you can adapt](https://api.census.gov/data/2019/acs/acs5/examples.html). \n",
    "\n",
    "*Hint:* Make sure to restrict your data request by state AND county if you want to keep it to a manageable size! You shouldn't need to request an API key for a small number of queries..\n",
    "\n",
    "*Hint:* Look at your data if you get the wrong answer to median income! For example, use `censusDf.describe()`, or `censusDf.sort_values(by='med_hh_income').head()`. You might need to replace some values with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6b16ca9b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86c8eb5795a4e76825e7e31ff50ee84b",
     "grade": false,
     "grade_id": "cell-087a1df3d3eb51b0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>median_hh_income</th>\n",
       "      <th>B25003_001E</th>\n",
       "      <th>B25003_002E</th>\n",
       "      <th>B25003_003E</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>tract</th>\n",
       "      <th>pct_renter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Tract 4827.02, Los Angeles County, Cali...</td>\n",
       "      <td>82917.0</td>\n",
       "      <td>802</td>\n",
       "      <td>579</td>\n",
       "      <td>223</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>482702</td>\n",
       "      <td>27.805486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Census Tract 5002.01, Los Angeles County, Cali...</td>\n",
       "      <td>114831.0</td>\n",
       "      <td>2209</td>\n",
       "      <td>1904</td>\n",
       "      <td>305</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500201</td>\n",
       "      <td>13.807153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Census Tract 5002.02, Los Angeles County, Cali...</td>\n",
       "      <td>133125.0</td>\n",
       "      <td>1460</td>\n",
       "      <td>1293</td>\n",
       "      <td>167</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500202</td>\n",
       "      <td>11.438356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Census Tract 5003, Los Angeles County, California</td>\n",
       "      <td>102875.0</td>\n",
       "      <td>1087</td>\n",
       "      <td>991</td>\n",
       "      <td>96</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500300</td>\n",
       "      <td>8.831647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Census Tract 5005, Los Angeles County, California</td>\n",
       "      <td>53500.0</td>\n",
       "      <td>894</td>\n",
       "      <td>610</td>\n",
       "      <td>284</td>\n",
       "      <td>06</td>\n",
       "      <td>037</td>\n",
       "      <td>500500</td>\n",
       "      <td>31.767338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                NAME  median_hh_income  \\\n",
       "0  Census Tract 4827.02, Los Angeles County, Cali...           82917.0   \n",
       "1  Census Tract 5002.01, Los Angeles County, Cali...          114831.0   \n",
       "2  Census Tract 5002.02, Los Angeles County, Cali...          133125.0   \n",
       "3  Census Tract 5003, Los Angeles County, California          102875.0   \n",
       "4  Census Tract 5005, Los Angeles County, California           53500.0   \n",
       "\n",
       "  B25003_001E B25003_002E B25003_003E state county   tract  pct_renter  \n",
       "0         802         579         223    06    037  482702   27.805486  \n",
       "1        2209        1904         305    06    037  500201   13.807153  \n",
       "2        1460        1293         167    06    037  500202   11.438356  \n",
       "3        1087         991          96    06    037  500300    8.831647  \n",
       "4         894         610         284    06    037  500500   31.767338  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Create new df containing ACS variables for tenture, median household income, and renters in LA County\n",
    "# Median household income: B19013_001E --> median_hh_income\n",
    "# Tenure: B25003_001E, B25003_002E, B25003_003E\n",
    "# Renter %: B25003_001E (total), B07013_003E (renters)\n",
    "\n",
    "# I used Class 1 solutions to make this function. In it, we are: (1) specifying the census variables to capture, (2) requesting variables with the API, (3) converting to JSON, (4) notes first row as header, (5) create % renter, (6) renames income var\n",
    "# From Lect. 4a: (7) remove null income values\n",
    "\n",
    "def census_data(countyFIPS):\n",
    "    var = 'B19013_001E,B25003_001E,B25003_002E,B25003_003E'\n",
    "    r = requests.get('https://api.census.gov/data/2019/acs/acs5?get=NAME,{}&for=tract:*&in=state:06%20county:{}'.format(var, countyFIPS))\n",
    "    censusdata = r.json()\n",
    "    censusDf = pd.DataFrame(censusdata[1:], columns=censusdata[0])\n",
    "    censusDf['pct_renter'] = censusDf.B25003_003E.astype(float) / censusDf.B25003_001E.astype(float) * 100\n",
    "    censusDf.rename(columns={'B19013_001E': 'median_hh_income'}, inplace=True)\n",
    "    censusDf['median_hh_income'] = pd.to_numeric(censusDf['median_hh_income'], errors='coerce')\n",
    "    censusDf.loc[censusDf.median_hh_income<0, 'median_hh_income'] = np.nan\n",
    "    return censusDf\n",
    "\n",
    "# Subset to LA County\n",
    "censusDf = census_data('037')\n",
    "censusDf.head(5)\n",
    "\n",
    "# Note: the np.nan was not working. ChatGPT suggested to add the line to convert to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "58482987",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "585870a71cdc9a29633a4e781b14e7d5",
     "grade": true,
     "grade_id": "cell-2d674b4f0e57e6dc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346\n",
      "53.273758713248945\n",
      "73242.84415584416\n"
     ]
    }
   ],
   "source": [
    "print (len(censusDf))\n",
    "print (censusDf.pct_renter.mean())\n",
    "print(censusDf.median_hh_income.mean())\n",
    "\n",
    "# Autograding tests - do not edit\n",
    "assert len(censusDf) == 2346\n",
    "assert censusDf.pct_renter.mean().round() == 53\n",
    "assert censusDf.median_hh_income.mean().round()==73243"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8146828",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9a4dde04d43ed5387005fbf72c319d7",
     "grade": false,
     "grade_id": "cell-10df2e93cc4cd1f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Create a new dataframe, `joinedDf`, with both your voting and census data, through a left join to the voting data. \n",
    "\n",
    "*Hint*: It will be easiest to join on the `tract` column (which is your index in `tractVotes`). Since everything is in LA County, you don't need to worry about the `state` or `county` fields.\n",
    "\n",
    "*Hint*: You'll need to convert the `tract` column in `censusDf` to an integer first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78c1fd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27a7efd4dc74b0334d4880c59f003b8b",
     "grade": false,
     "grade_id": "cell-7826b19a96730b22",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "joinedDf = 9999\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49062cce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bf516602b49234ddd1cc63807b8acf0",
     "grade": true,
     "grade_id": "cell-1cd1c76f5b8264c9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(joinedDf.pct_renter.count())\n",
    "print(joinedDf.pct_renter.mean())\n",
    "\n",
    "# Autograding tests - do not edit\n",
    "assert joinedDf.pct_renter.count() == 2318\n",
    "assert joinedDf.pct_renter.mean().round() == 53"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccab3db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "abefd65bcabb67fb3b70520ad7fb4292",
     "grade": false,
     "grade_id": "cell-0473e50f37e6f3ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's start with a simple random forests model with the following *x* variables:\n",
    "\n",
    "* Median HH income\n",
    "* Percent of HHs that are renters\n",
    "* Presidential vote (2-party share of Democrat voters, i.e. the percent voting for Biden vs Trump, with other candidates ignored)\n",
    "\n",
    "And the following *y* variable\n",
    "* Whether Prop 21 won (received a majority) in that census tract. This should be `True` if the Yeses got more votes than the Nos.\n",
    "\n",
    "(Yes, vote share in each tract would be better to predict rather than a binary variable - hold off on that for the challenge problem.)\n",
    "\n",
    "Create the relevant columns, `pct_biden` and `PR_21_won`, in your `joinedDf` dataframe. \n",
    "\n",
    "Then split your dataframe into a training sample (75%) and a test sample (25%). *Hint*: Drop the `NaNs` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00189327",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65fd2c2e8897c1b97853ab1fbbde6224",
     "grade": false,
     "grade_id": "cell-f292cd5bba490d15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "X_train, X_test, y_train, y_test = 999, 999, 999, 999\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37924f00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9e3f762c36076b242a09e68f1422eb9",
     "grade": true,
     "grade_id": "cell-51a28332d08e392f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(X_train.pct_biden.mean())\n",
    "print(y_train.mean())\n",
    "\n",
    "# Autograding tests - do not edit\n",
    "assert len(X_train) == 1731\n",
    "assert len(X_train.columns) == 3\n",
    "assert len(X_test) == 578\n",
    "assert len(X_train) == len(y_train)\n",
    "assert len(X_test) == len(y_test)\n",
    "assert X_train.pct_biden.mean().round() == 74\n",
    "assert y_train.mean().round(1) == 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a095a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47be54094151a23829637bb621579c23",
     "grade": false,
     "grade_id": "cell-da525eb9a304953d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Estimate a random forests model, and assign the predicted *y* values from your *test* sample to `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afd7b7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20535f599ecfe005d16d51a36decb39d",
     "grade": false,
     "grade_id": "cell-18655f54613bacb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba581a2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3c939c242a2e2c97ac1d6beed36510e",
     "grade": true,
     "grade_id": "cell-633c221bbc5dda5e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(y_pred))\n",
    "print(y_pred.mean())\n",
    "\n",
    "# Autograding tests - do not edit\n",
    "assert len(y_pred)==len(y_test)\n",
    "assert y_pred.mean().round(1) == 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4319c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "106147275ab4f5520232b7cb2f96afa5",
     "grade": false,
     "grade_id": "cell-907f10cfdc92c141",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at some measures of fit. Plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c942a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a217f1332e891585b32e8647876c8e04",
     "grade": true,
     "grade_id": "cell-c73405d47229d9c2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b1fb72",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15f7f3d9f89db03a090c94c5d9b8e8c2",
     "grade": false,
     "grade_id": "cell-f4a7868979483ed5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, plot the importance of each of the 3 predictor variables, in the same way as we did in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8efe8f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81d38608175af20135e30ea93a693703",
     "grade": true,
     "grade_id": "cell-6db4a17c87ddf643",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b82113",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f372fa06efc2d9978b8beca6859f3250",
     "grade": false,
     "grade_id": "cell-0a6b521f6268911b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Comment on your interpretation of the results and the confusion matrix. What do they tell you about:\n",
    "- your predictive accuracy\n",
    "- which variables are important\n",
    "- how you might refine the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6b202",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "927dfce73cceaf93bb709dbc7a116b10",
     "grade": true,
     "grade_id": "cell-e2b3e80aad8c47a2",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61901bb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c176d496ec3c329b1950b0336133986",
     "grade": false,
     "grade_id": "cell-ffd460ba8c5df1e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Challenge Problem\n",
    "Remember, you need to do at least two of these challenge problems this quarter.\n",
    "\n",
    "This challenge problem is open ended for you to take in a direction that you are most interested in. Here are some suggestions (do 1 or 2 of these):\n",
    "\n",
    "* Extend the random forests model to predict vote share on Prop 21, rather than a binary yes/no, and using additional variables. See suggestions below. \n",
    "* Use a neural network instead. How much does this improve the predictions? Use charts to compare the predictions to the random forests model.\n",
    "* Examine the geographic distribution of the predictions, through mapping the prediction errors. Where does your model perform best? Does this give you pointers as to how to improve your model?\n",
    "\n",
    "In all cases, write some brief interpretation in a markdown cell.\n",
    "\n",
    "*Predicting a continuous variable*\n",
    "\n",
    "Classification problems are typically binary or categorical - which category do you predict a given observation to fall into. In some cases, however, we might want to predict a continuous variable, such as the percentage of \"yes\" votes on Prop 21. For this we can use `RandomForestRegressor`, which works very similarly to `RandomForestClassifier`. You can follow exactly the same steps: create the `rf` object, fit the model, and predict using the test sample.\n",
    "\n",
    "How do you evaluate model performance? Since we have a continuous variable, we can't use the confusion matrix. But we can look at the absolute error (each predicted value minus the true value for each of our test precincts). I.e., `abs(y_pred-y_test)`. You can also do a scatter plot of the predicted values against the true values. The divergence from the 45 degree line is a good indication of how well the model fits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:uds]",
   "language": "python",
   "name": "conda-env-uds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
